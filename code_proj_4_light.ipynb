{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coding Project: Differentiable NAS\n",
    "\n",
    "* ### Based on the paper:H. Liu, K. Simonyanand Y. Yang, “DARTS: Differentiable Architecture Search,” International Conference on Learning Representations (ICLR),2019\n",
    "\n",
    "* ### Assignment\n",
    "\n",
    "  1. Find a codebase of this paper (the original DARTS implementation is available, and you can find a few variants), download the CIFAR10 and CIFAR100 datasets\n",
    "\n",
    "  **The dataset and codebase have already upload in the OBS of Huawei Cloud Platform, you can use it directly in the ModelArts.**\n",
    "\n",
    "  1. Run the basic code on the server, with the standard configuration of the selected paperon CIFAR10 (take the computational costs into consideration)\n",
    "  \n",
    "  2. Finish the required task and one of the optional tasks (see the following slides) –of course, you can do more than one optional tasks if you wish (bonus points)\n",
    "  3. If you have more ideas, please specify a new task by yourself (bonus points)\n",
    "  4. Remember: integrate your results into your reading report\n",
    "  5. Date assigned: Nov. 19, 2019;    Date Due: Dec 14, 2020\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Task\n",
    "\n",
    "* The basic training and testing pipeline\n",
    "    * Run a complete search process with DARTS or any of its variant on CIFAR10 (PC-DARTS is preferred due to the low costs)\n",
    "    * Note: due to the limitation of computational resource, you may not have sufficient resource to perform the re-training process\n",
    "    * Pay attention to the hyper-parameters (config, epochs, etc.)\n",
    "* Questions that should be answered in the report\n",
    "    * Paste complete training and testing curves and the final architecture\n",
    "    * Report the training and validation accuracy throughout the process\n",
    "    * How is performance changing with the number of iterations?\n",
    "    * Any other significant features that can be recognized in the curves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "One time installation of required libraries from requirement.txt and creating data path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘data’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "# !pip3 install torch\n",
    "!mkdir data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Downloading CIFAR10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully download file cv-course-public/coding-1/cifar-10-python.tar.gz from OBS to local ./data/cifar-10-python.tar.gz\n"
     ]
    }
   ],
   "source": [
    "from dataset.dataset_dowloader_ import *\n",
    "\n",
    "cifar10_dowloader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start!\n",
    "\n",
    "We are going to search couple of genotypes. We choose next combinations of initial hyperparams:\n",
    "\n",
    "  * `N3-E50-CS6-BS256-CT10-BT96` - classic\n",
    "     - `N3` - nodes number (4) in each cell during search\n",
    "     - `E50` - epochs number (50) for searching final genotype\n",
    "     - `CS6` - cell number (8) as a \"layer\"\n",
    "     - `BS256` - batch size (256) from CIFAR10 (training portion of data is 0.5 - 25k) during search\n",
    "     - `CT10` - nodes number (4) in each cell during eval\n",
    "     - `BT96` - batch size (256) from CIFAR10 (training portion of data is 0.5 - 25k) during eval\n",
    "     \n",
    "  * `N3-E50-CS6-BS128-CT10-BT96` - batch size (128)\n",
    "     \n",
    "  * `N3-E100-CS6-BS256-CT10-BT96` - epochs number (100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train_search.py --data='./data' --save='N3-E50-CS6-BS256-CT10-BT96' --nodes=3 --multiplier=3 --layers=6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python train_search.py --data='./data' --save='N3-E50-CS6-BS128-CT10-BT96' --nodes=3 --multiplier=3 --layers=6 --batch_size=128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment dir : search-N3-E100-CS6-BS256-CT10-BT96-20200301-013736\n",
      "03/01 01:37:36 AM gpu device = 0\n",
      "03/01 01:37:36 AM args = Namespace(arch_learning_rate=0.0006, arch_weight_decay=0.001, batch_size=256, cutout=False, cutout_length=16, data='./data', drop_path_prob=0.3, epochs=100, gpu=0, grad_clip=5, init_channels=16, layers=6, learning_rate=0.1, learning_rate_min=0.001, model_path='saved_models', momentum=0.9, multiplier=3, nodes=3, report_freq=50, save='search-N3-E100-CS6-BS256-CT10-BT96-20200301-013736', seed=2, set='cifar10', train_portion=0.5, unrolled=False, weight_decay=0.0003)\n",
      "03/01 01:37:39 AM param size = 0.134410MB\n",
      "Using downloaded and verified file: ./data/cifar-10-python.tar.gz\n",
      "03/01 01:37:41 AM epoch 0 lr 1.000000e-01\n",
      "03/01 01:37:41 AM genotype_debug = Genotype(normal=[('dil_conv_3x3', 'max_pool_3x3', 0), ('dil_conv_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 1), ('skip_connect', 'max_pool_3x3', 2), ('sep_conv_3x3', 'avg_pool_3x3', 0), ('avg_pool_3x3', 'max_pool_3x3', 0), ('skip_connect', 'avg_pool_3x3', 2), ('dil_conv_3x3', 'sep_conv_3x3', 1), ('dil_conv_5x5', 'max_pool_3x3', 3)], normal_concat=range(2, 5), reduce=[('avg_pool_3x3', 'max_pool_3x3', 0), ('sep_conv_5x5', 'skip_connect', 1), ('sep_conv_5x5', 'skip_connect', 0), ('max_pool_3x3', 'max_pool_3x3', 2), ('max_pool_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 2), ('max_pool_3x3', 'max_pool_3x3', 0), ('skip_connect', 'avg_pool_3x3', 3)], reduce_concat=range(2, 5))\n",
      "03/01 01:37:41 AM genotype = Genotype(normal=[('dil_conv_3x3', 0), ('dil_conv_3x3', 1), ('max_pool_3x3', 1), ('skip_connect', 2), ('avg_pool_3x3', 0), ('skip_connect', 2)], normal_concat=range(2, 5), reduce=[('avg_pool_3x3', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('max_pool_3x3', 2), ('max_pool_3x3', 1), ('max_pool_3x3', 2)], reduce_concat=range(2, 5))\n",
      "tensor([[0.1251, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1249],\n",
      "        [0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252, 0.1249],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1248, 0.1252, 0.1251, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1252, 0.1249, 0.1250, 0.1248, 0.1250, 0.1252, 0.1249],\n",
      "        [0.1252, 0.1248, 0.1248, 0.1252, 0.1248, 0.1250, 0.1251, 0.1251],\n",
      "        [0.1251, 0.1249, 0.1252, 0.1251, 0.1248, 0.1247, 0.1252, 0.1250],\n",
      "        [0.1250, 0.1249, 0.1249, 0.1249, 0.1252, 0.1251, 0.1252, 0.1248],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1250, 0.1251]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1251, 0.1251, 0.1250, 0.1248],\n",
      "        [0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],\n",
      "        [0.1250, 0.1248, 0.1249, 0.1252, 0.1251, 0.1252, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1249],\n",
      "        [0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1252, 0.1251, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1249],\n",
      "        [0.1252, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249, 0.1250, 0.1251],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1252, 0.1249, 0.1250, 0.1248, 0.1249]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([0.3330, 0.3336, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "train_search.py:189: UserWarning: torch.nn.utils.clip_grad_norm is now deprecated in favor of torch.nn.utils.clip_grad_norm_.\n",
      "  nn.utils.clip_grad_norm(model.parameters(), args.grad_clip)\n",
      "03/01 01:37:44 AM train 000 2.313002e+00 7.812500 50.781250\n",
      "03/01 01:38:20 AM train 050 1.876398e+00 29.028799 82.268689\n",
      "03/01 01:38:55 AM train_acc 33.224000\n",
      "03/01 01:38:55 AM epoch 1 lr 9.997557e-02\n",
      "03/01 01:38:55 AM genotype_debug = Genotype(normal=[('dil_conv_3x3', 'max_pool_3x3', 0), ('dil_conv_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 1), ('skip_connect', 'max_pool_3x3', 2), ('sep_conv_3x3', 'avg_pool_3x3', 0), ('avg_pool_3x3', 'max_pool_3x3', 0), ('skip_connect', 'avg_pool_3x3', 2), ('dil_conv_3x3', 'sep_conv_3x3', 1), ('dil_conv_5x5', 'max_pool_3x3', 3)], normal_concat=range(2, 5), reduce=[('avg_pool_3x3', 'max_pool_3x3', 0), ('sep_conv_5x5', 'skip_connect', 1), ('sep_conv_5x5', 'skip_connect', 0), ('max_pool_3x3', 'max_pool_3x3', 2), ('max_pool_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 2), ('max_pool_3x3', 'max_pool_3x3', 0), ('skip_connect', 'avg_pool_3x3', 3)], reduce_concat=range(2, 5))\n",
      "03/01 01:38:55 AM genotype = Genotype(normal=[('dil_conv_3x3', 0), ('dil_conv_3x3', 1), ('max_pool_3x3', 1), ('skip_connect', 2), ('avg_pool_3x3', 0), ('skip_connect', 2)], normal_concat=range(2, 5), reduce=[('avg_pool_3x3', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('max_pool_3x3', 2), ('max_pool_3x3', 1), ('max_pool_3x3', 2)], reduce_concat=range(2, 5))\n",
      "tensor([[0.1251, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1249],\n",
      "        [0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252, 0.1249],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1248, 0.1252, 0.1251, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1252, 0.1249, 0.1250, 0.1248, 0.1250, 0.1252, 0.1249],\n",
      "        [0.1252, 0.1248, 0.1248, 0.1252, 0.1248, 0.1250, 0.1251, 0.1251],\n",
      "        [0.1251, 0.1249, 0.1252, 0.1251, 0.1248, 0.1247, 0.1252, 0.1250],\n",
      "        [0.1250, 0.1249, 0.1249, 0.1249, 0.1252, 0.1251, 0.1252, 0.1248],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1250, 0.1251]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1251, 0.1251, 0.1250, 0.1248],\n",
      "        [0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],\n",
      "        [0.1250, 0.1248, 0.1249, 0.1252, 0.1251, 0.1252, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1249],\n",
      "        [0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1252, 0.1251, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1249],\n",
      "        [0.1252, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249, 0.1250, 0.1251],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1252, 0.1249, 0.1250, 0.1248, 0.1249]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([0.3330, 0.3336, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "03/01 01:38:56 AM train 000 1.608163e+00 34.765625 90.234375\n",
      "03/01 01:39:32 AM train 050 1.517080e+00 43.190870 91.628370\n",
      "03/01 01:40:06 AM train_acc 44.900000\n",
      "03/01 01:40:06 AM epoch 2 lr 9.990232e-02\n",
      "03/01 01:40:06 AM genotype_debug = Genotype(normal=[('dil_conv_3x3', 'max_pool_3x3', 0), ('dil_conv_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 1), ('skip_connect', 'max_pool_3x3', 2), ('sep_conv_3x3', 'avg_pool_3x3', 0), ('avg_pool_3x3', 'max_pool_3x3', 0), ('skip_connect', 'avg_pool_3x3', 2), ('dil_conv_3x3', 'sep_conv_3x3', 1), ('dil_conv_5x5', 'max_pool_3x3', 3)], normal_concat=range(2, 5), reduce=[('avg_pool_3x3', 'max_pool_3x3', 0), ('sep_conv_5x5', 'skip_connect', 1), ('sep_conv_5x5', 'skip_connect', 0), ('max_pool_3x3', 'max_pool_3x3', 2), ('max_pool_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 2), ('max_pool_3x3', 'max_pool_3x3', 0), ('skip_connect', 'avg_pool_3x3', 3)], reduce_concat=range(2, 5))\n",
      "03/01 01:40:06 AM genotype = Genotype(normal=[('dil_conv_3x3', 0), ('dil_conv_3x3', 1), ('max_pool_3x3', 1), ('skip_connect', 2), ('avg_pool_3x3', 0), ('skip_connect', 2)], normal_concat=range(2, 5), reduce=[('avg_pool_3x3', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('max_pool_3x3', 2), ('max_pool_3x3', 1), ('max_pool_3x3', 2)], reduce_concat=range(2, 5))\n",
      "tensor([[0.1251, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1249],\n",
      "        [0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252, 0.1249],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1248, 0.1252, 0.1251, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1252, 0.1249, 0.1250, 0.1248, 0.1250, 0.1252, 0.1249],\n",
      "        [0.1252, 0.1248, 0.1248, 0.1252, 0.1248, 0.1250, 0.1251, 0.1251],\n",
      "        [0.1251, 0.1249, 0.1252, 0.1251, 0.1248, 0.1247, 0.1252, 0.1250],\n",
      "        [0.1250, 0.1249, 0.1249, 0.1249, 0.1252, 0.1251, 0.1252, 0.1248],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1250, 0.1251]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1251, 0.1251, 0.1250, 0.1248],\n",
      "        [0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],\n",
      "        [0.1250, 0.1248, 0.1249, 0.1252, 0.1251, 0.1252, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1249],\n",
      "        [0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1252, 0.1251, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1249],\n",
      "        [0.1252, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249, 0.1250, 0.1251],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1252, 0.1249, 0.1250, 0.1248, 0.1249]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([0.3330, 0.3336, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "03/01 01:40:07 AM train 000 1.326397e+00 53.906250 93.750000\n",
      "03/01 01:40:43 AM train 050 1.360932e+00 50.375306 93.642770\n",
      "03/01 01:41:16 AM train_acc 51.804000\n",
      "03/01 01:41:16 AM epoch 3 lr 9.978032e-02\n",
      "03/01 01:41:16 AM genotype_debug = Genotype(normal=[('dil_conv_3x3', 'max_pool_3x3', 0), ('dil_conv_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 1), ('skip_connect', 'max_pool_3x3', 2), ('sep_conv_3x3', 'avg_pool_3x3', 0), ('avg_pool_3x3', 'max_pool_3x3', 0), ('skip_connect', 'avg_pool_3x3', 2), ('dil_conv_3x3', 'sep_conv_3x3', 1), ('dil_conv_5x5', 'max_pool_3x3', 3)], normal_concat=range(2, 5), reduce=[('avg_pool_3x3', 'max_pool_3x3', 0), ('sep_conv_5x5', 'skip_connect', 1), ('sep_conv_5x5', 'skip_connect', 0), ('max_pool_3x3', 'max_pool_3x3', 2), ('max_pool_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 2), ('max_pool_3x3', 'max_pool_3x3', 0), ('skip_connect', 'avg_pool_3x3', 3)], reduce_concat=range(2, 5))\n",
      "03/01 01:41:16 AM genotype = Genotype(normal=[('dil_conv_3x3', 0), ('dil_conv_3x3', 1), ('max_pool_3x3', 1), ('skip_connect', 2), ('avg_pool_3x3', 0), ('skip_connect', 2)], normal_concat=range(2, 5), reduce=[('avg_pool_3x3', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('max_pool_3x3', 2), ('max_pool_3x3', 1), ('max_pool_3x3', 2)], reduce_concat=range(2, 5))\n",
      "tensor([[0.1251, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1249],\n",
      "        [0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252, 0.1249],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1248, 0.1252, 0.1251, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1252, 0.1249, 0.1250, 0.1248, 0.1250, 0.1252, 0.1249],\n",
      "        [0.1252, 0.1248, 0.1248, 0.1252, 0.1248, 0.1250, 0.1251, 0.1251],\n",
      "        [0.1251, 0.1249, 0.1252, 0.1251, 0.1248, 0.1247, 0.1252, 0.1250],\n",
      "        [0.1250, 0.1249, 0.1249, 0.1249, 0.1252, 0.1251, 0.1252, 0.1248],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1250, 0.1251]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1251, 0.1251, 0.1250, 0.1248],\n",
      "        [0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],\n",
      "        [0.1250, 0.1248, 0.1249, 0.1252, 0.1251, 0.1252, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1249],\n",
      "        [0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1252, 0.1251, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1249],\n",
      "        [0.1252, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249, 0.1250, 0.1251],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1252, 0.1249, 0.1250, 0.1248, 0.1249]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([0.3330, 0.3336, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "03/01 01:41:17 AM train 000 1.277565e+00 58.203125 95.312500\n",
      "03/01 01:41:53 AM train 050 1.229008e+00 55.591299 95.128676\n",
      "03/01 01:42:27 AM train_acc 56.876000\n",
      "03/01 01:42:27 AM epoch 4 lr 9.960968e-02\n",
      "03/01 01:42:27 AM genotype_debug = Genotype(normal=[('dil_conv_3x3', 'max_pool_3x3', 0), ('dil_conv_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 1), ('skip_connect', 'max_pool_3x3', 2), ('sep_conv_3x3', 'avg_pool_3x3', 0), ('avg_pool_3x3', 'max_pool_3x3', 0), ('skip_connect', 'avg_pool_3x3', 2), ('dil_conv_3x3', 'sep_conv_3x3', 1), ('dil_conv_5x5', 'max_pool_3x3', 3)], normal_concat=range(2, 5), reduce=[('avg_pool_3x3', 'max_pool_3x3', 0), ('sep_conv_5x5', 'skip_connect', 1), ('sep_conv_5x5', 'skip_connect', 0), ('max_pool_3x3', 'max_pool_3x3', 2), ('max_pool_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 1), ('max_pool_3x3', 'max_pool_3x3', 2), ('max_pool_3x3', 'max_pool_3x3', 0), ('skip_connect', 'avg_pool_3x3', 3)], reduce_concat=range(2, 5))\n",
      "03/01 01:42:27 AM genotype = Genotype(normal=[('dil_conv_3x3', 0), ('dil_conv_3x3', 1), ('max_pool_3x3', 1), ('skip_connect', 2), ('avg_pool_3x3', 0), ('skip_connect', 2)], normal_concat=range(2, 5), reduce=[('avg_pool_3x3', 0), ('sep_conv_5x5', 1), ('sep_conv_5x5', 0), ('max_pool_3x3', 2), ('max_pool_3x3', 1), ('max_pool_3x3', 2)], reduce_concat=range(2, 5))\n",
      "tensor([[0.1251, 0.1250, 0.1250, 0.1250, 0.1249, 0.1250, 0.1251, 0.1249],\n",
      "        [0.1249, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1252, 0.1249],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1248, 0.1252, 0.1251, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1252, 0.1249, 0.1250, 0.1248, 0.1250, 0.1252, 0.1249],\n",
      "        [0.1252, 0.1248, 0.1248, 0.1252, 0.1248, 0.1250, 0.1251, 0.1251],\n",
      "        [0.1251, 0.1249, 0.1252, 0.1251, 0.1248, 0.1247, 0.1252, 0.1250],\n",
      "        [0.1250, 0.1249, 0.1249, 0.1249, 0.1252, 0.1251, 0.1252, 0.1248],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1251, 0.1248, 0.1250, 0.1249, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1250, 0.1250, 0.1249, 0.1249, 0.1250, 0.1251]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([[0.1250, 0.1249, 0.1251, 0.1249, 0.1251, 0.1251, 0.1250, 0.1248],\n",
      "        [0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1251, 0.1251, 0.1249],\n",
      "        [0.1250, 0.1248, 0.1249, 0.1252, 0.1251, 0.1252, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1250, 0.1249, 0.1250, 0.1249, 0.1249],\n",
      "        [0.1249, 0.1251, 0.1251, 0.1249, 0.1250, 0.1250, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1252, 0.1251, 0.1250, 0.1250, 0.1249, 0.1250, 0.1249],\n",
      "        [0.1250, 0.1251, 0.1251, 0.1248, 0.1250, 0.1250, 0.1250, 0.1249],\n",
      "        [0.1252, 0.1251, 0.1249, 0.1249, 0.1249, 0.1249, 0.1250, 0.1251],\n",
      "        [0.1251, 0.1250, 0.1251, 0.1252, 0.1249, 0.1250, 0.1248, 0.1249]],\n",
      "       device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "tensor([0.3330, 0.3336, 0.3334], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "03/01 01:42:28 AM train 000 1.089604e+00 59.765625 96.093750\n"
     ]
    }
   ],
   "source": [
    "!python train_search.py --data='./data' --save='N3-E100-CS6-BS256-CT10-BT96' --nodes=3 --multiplier=3 --layers=6 --epochs=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python train.py --auxiliary --cutout --arch='' --data='./data' --save='N4-E50-CS8-BS256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --auxiliary --cutout --arch='N4-E50-CS8-BS128-20200118-105259' --data='./data' --save='N4-E50-CS8-BS128'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --auxiliary --cutout --arch='N4-E50-CS4-BS256-20200118-105518' --data='./data' --save='N4-E50-CS4-BS256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --auxiliary --cutout --arch='N4-E20-CS8-BS256-20200118-105659' --data='./data' --save='N4-E20-CS8-BS256'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch-1.0.0",
   "language": "python",
   "name": "pytorch-1.0.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
